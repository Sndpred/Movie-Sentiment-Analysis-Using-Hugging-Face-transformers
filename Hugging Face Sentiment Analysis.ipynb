{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22274165-673c-4dc0-bbf7-c76c78d9227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path: /opt/anaconda3/envs/hf-project/bin/python\n",
      "Python version: 3.10.18 (main, Jun  5 2025, 08:37:47) [Clang 14.0.6 ]\n",
      "✅ You're in the hf-project environment!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python path:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# Check if we're in the right environment\n",
    "if \"hf-project\" in sys.executable:\n",
    "    print(\"You're in the hf-project environment!\")\n",
    "else:\n",
    "    print(\"You might not be in the hf-project environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6905238-c1a6-4172-be4d-48d9d641f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All packages imported successfully!\n",
      "PyTorch version: 2.8.0\n",
      "Transformers version: 4.55.4\n",
      "Device available: CPU\n"
     ]
    }
   ],
   "source": [
    "# Test all our key imports\n",
    "try:\n",
    "    import torch\n",
    "    import transformers\n",
    "    import datasets\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    print(\"All packages imported successfully!\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "    print(f\"Device available: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c788fb0-ef59-4646-84ce-b9a5998d7217",
   "metadata": {},
   "source": [
    "<h3>Step 1: Load and Explore Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665ba279-a1c5-4af4-9222-9cff09ff6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f7464c6-4001-4448-a434-a8593c873406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (25000, 2)\n",
      "Columns: ['text', 'label']\n",
      "Dataset Shape:(1000, 2)\n",
      "Label Distribution:\n",
      "label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- POSITIVE Example ---\n",
      "Review: The main reason to see this film is Warren William, who is in top form as the shyster campaign manager. He is electric, constantly finding ways to fool the public and defeat the opposing party in the ...\n",
      "\n",
      "--- NEGATIVE Example ---\n",
      "Review: I rented this film yesterday mostly due to the good-looking art and the summary given on the back of the jacket. After popping it into my DVD player I re-examined the jacket cover and even though I to...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load popular sentiment analysis dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "#dataset = load_dataset(\"imdb\", split=\"train[:1000]\") #using 1000 samples\n",
    "\n",
    "#convert to pandas\n",
    "df = pd.DataFrame(dataset)\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "#get 500 positive and negative samples\n",
    "df_pos = df[df['label'] == 1].sample(n=500, random_state =42)\n",
    "df_neg = df[df['label'] == 0].sample(n=500, random_state =42)\n",
    "\n",
    "#combine and shuffle\n",
    "df = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset Shape:{df.shape}\")\n",
    "print(f\"Label Distribution:\")\n",
    "print(df['label'].value_counts().sort_index())\n",
    "\n",
    "# Show examples of both labels\n",
    "print(\"\\n--- POSITIVE Example ---\")\n",
    "pos_example = df[df['label'] == 1].iloc[0]\n",
    "print(f\"Review: {pos_example['text'][:200]}...\")\n",
    "\n",
    "print(\"\\n--- NEGATIVE Example ---\")\n",
    "neg_example = df[df['label'] == 0].iloc[0]\n",
    "print(f\"Review: {neg_example['text'][:200]}...\")\n",
    "\n",
    "# visualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['label'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Label (0=Negative, 1=Positive)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae68415-8c1b-4f3b-8811-a68b4951657b",
   "metadata": {},
   "source": [
    "<h3>Step 2: Compare Pre-trained Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd34bbd0-a196-4609-aa15-fa6802f7b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models on 10 sample reviews\n",
      "\n",
      "Testing: cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "/opt/anaconda3/envs/hf-project/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 4.23 seconds\n",
      "Sample prediction: {'label': 'negative', 'score': 0.8286230564117432}\n",
      "\n",
      "First 3 predictions: ['negative', 'positive', 'negative']\n",
      "\n",
      "Testing: distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 0.53 seconds\n",
      "Sample prediction: {'label': 'NEGATIVE', 'score': 0.9949365854263306}\n",
      "\n",
      "First 3 predictions: ['NEGATIVE', 'POSITIVE', 'NEGATIVE']\n",
      "\n",
      "Testing: nlptown/bert-base-multilingual-uncased-sentiment\n",
      "Completed in 2.65 seconds\n",
      "Sample prediction: {'label': '2 stars', 'score': 0.4008040726184845}\n",
      "\n",
      "First 3 predictions: ['2 stars', '5 stars', '2 stars']\n",
      "\n",
      "Successfully tested 3 models!\n",
      "\n",
      "=== MODEL PERFORMANCE SUMMARY ===\n",
      "twitter-roberta-base-sentiment-latest: 4.23s\n",
      "distilbert-base-uncased-finetuned-sst-2-english: 0.53s\n",
      "bert-base-multilingual-uncased-sentiment: 2.65s\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "#initialize results list\n",
    "results = []\n",
    "\n",
    "#define models to test\n",
    "models_to_test = [\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "    \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "]\n",
    "\n",
    "test_sample = df.sample(n=10, random_state=42)\n",
    "\n",
    "print(\"Testing models on 10 sample reviews\\n\")\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Testing: {model_name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        #load pipeline\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=model_name, return_all_scores=False)\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = []\n",
    "        for text in test_sample['text']:\n",
    "            # Truncate text to avoid memory issues\n",
    "            truncated_text = text[:512]  \n",
    "            pred = classifier(truncated_text)\n",
    "            predictions.append(pred[0])\n",
    "        \n",
    "        # Calculate time taken\n",
    "        time_taken = time.time() - start_time\n",
    "        \n",
    "        # Store results\n",
    "        model_result = {\n",
    "            'model': model_name.split('/')[-1],  # Just the model name\n",
    "            'time_taken': round(time_taken, 2),\n",
    "            'predictions': predictions\n",
    "        }\n",
    "        results.append(model_result)\n",
    "        \n",
    "        print(f\"Completed in {time_taken:.2f} seconds\")\n",
    "        print(f\"Sample prediction: {predictions[0]}\\n\")\n",
    "        print(f\"First 3 predictions: {[p['label'] for p in predictions[:3]]}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {model_name}: {e}\\n\")\n",
    "\n",
    "print(f\"Successfully tested {len(results)} models!\")\n",
    "\n",
    "#show summary\n",
    "\n",
    "if results:\n",
    "    print(\"\\n=== MODEL PERFORMANCE SUMMARY ===\")\n",
    "    for result in results:\n",
    "        print(f\"{result['model']}: {result['time_taken']}s\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27ae4dc-742f-420f-8840-a03c42fb03fb",
   "metadata": {},
   "source": [
    "<h3>Model Performance Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "490fe370-56c6-4a70-9ee6-1891970171af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL ANALYSIS ===\n",
      "\n",
      "SPEED RANKING:\n",
      "1. DistilBERT: 0.48s (FASTEST)\n",
      "2. RoBERTa: 1.05s\n",
      "3. Multilingual BERT: 1.21s (SLOWEST)\n",
      "\n",
      "LABEL FORMATS:\n",
      "• RoBERTa: 'positive'/'negative' (binary)\n",
      "• DistilBERT: 'POSITIVE'/'NEGATIVE' (binary, uppercase)\n",
      "• Multilingual BERT: '1-5 stars' (multi-class rating)\n",
      "\n",
      "Evaluate accuracy on our test sample:\n",
      "twitter-roberta-base-sentiment-latest: 60.0% accuracy (6/10)\n",
      "distilbert-base-uncased-finetuned-sst-2-english: 90.0% accuracy (9/10)\n",
      "bert-base-multilingual-uncased-sentiment: 80.0% accuracy (8/10)\n",
      "\n",
      "Ground truth sample: ['negative', 'positive', 'negative', 'positive', 'negative']\n"
     ]
    }
   ],
   "source": [
    "# Analyze the results more systematically\n",
    "\n",
    "print(\"=== MODEL ANALYSIS ===\\n\")\n",
    "\n",
    "# Performance summary\n",
    "print(\"SPEED RANKING:\")\n",
    "print(\"1. DistilBERT: 0.48s (FASTEST)\")\n",
    "print(\"2. RoBERTa: 1.05s\") \n",
    "print(\"3. Multilingual BERT: 1.21s (SLOWEST)\")\n",
    "\n",
    "print(\"\\nLABEL FORMATS:\")\n",
    "print(\"• RoBERTa: 'positive'/'negative' (binary)\")\n",
    "print(\"• DistilBERT: 'POSITIVE'/'NEGATIVE' (binary, uppercase)\")\n",
    "print(\"• Multilingual BERT: '1-5 stars' (multi-class rating)\")\n",
    "\n",
    "print(\"\\nEvaluate accuracy on our test sample:\")\n",
    "\n",
    "# Get ground truth for our test sample\n",
    "ground_truth = ['positive' if label == 1 else 'negative' for label in test_sample['label']]\n",
    "\n",
    "# Convert predictions to standard format\n",
    "def standardize_predictions(predictions, model_name):\n",
    "    if 'roberta' in model_name:\n",
    "        return [p['label'].lower() for p in predictions]\n",
    "    elif 'distilbert' in model_name:\n",
    "        return [p['label'].lower() for p in predictions]\n",
    "    else:  # multilingual bert uses star ratings\n",
    "        # Convert star ratings to sentiment (1-2 stars = negative, 4-5 stars = positive, 3 = neutral->negative for simplicity)\n",
    "        converted = []\n",
    "        for p in predictions:\n",
    "            if p['label'] in ['1 star', '2 stars']:\n",
    "                converted.append('negative')\n",
    "            elif p['label'] in ['4 stars', '5 stars']:\n",
    "                converted.append('positive')\n",
    "            else:  # 3 stars - treat as negative for binary classification\n",
    "                converted.append('negative')\n",
    "        return converted\n",
    "\n",
    "# Calculate accuracy for each model\n",
    "for result in results:\n",
    "    model_name = result['model']\n",
    "    std_preds = standardize_predictions(result['predictions'], model_name)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = sum(1 for true, pred in zip(ground_truth, std_preds) if true == pred)\n",
    "    accuracy = correct / len(ground_truth)\n",
    "    \n",
    "    print(f\"{model_name}: {accuracy:.1%} accuracy ({correct}/{len(ground_truth)})\")\n",
    "\n",
    "print(f\"\\nGround truth sample: {ground_truth[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbe5371-b84b-487f-8f2e-26d897fab2ef",
   "metadata": {},
   "source": [
    "<h3>Step 3: Fine-tune DistilBERT on Our Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b0d9b6f-cf7d-48c3-8ec7-3fcedfdc0f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DistilBERT fine-tuning process...\n",
      "\n",
      "Training samples: 800\n",
      "Test samples: 200\n",
      "Train label distribution: [400 400]\n",
      "Test label distribution: [100 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79488fe50544717829dfade2b20e379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9406b73dc964fb09ed1d6694aed2baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data preparation complete!\n",
      "Sample tokenized length: 512 tokens\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, \n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting DistilBERT fine-tuning process...\\n\")\n",
    "\n",
    "# 1. Prepare the data\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Split our data (80% train, 20% test)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'].tolist(), \n",
    "    df['label'].tolist(), \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['label']  # Keep same proportion of pos/neg in both splits\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Test samples: {len(test_texts)}\")\n",
    "print(f\"Train label distribution: {np.bincount(train_labels)}\")\n",
    "print(f\"Test label distribution: {np.bincount(test_labels)}\")\n",
    "\n",
    "# 2. Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({'text': train_texts, 'labels': train_labels})\n",
    "test_dataset = Dataset.from_dict({'text': test_texts, 'labels': test_labels})\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"\\nData preparation complete!\")\n",
    "print(f\"Sample tokenized length: {len(train_dataset[0]['input_ids'])} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801e282-2019-4d3c-9a69-c7d6eeb85a85",
   "metadata": {},
   "source": [
    "<h3>Step 4: Configure and Start Fine-tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3676e775-9eb6-43ef-9832-86c21f5b45f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/dvzwkq2d1w93p5j9kgshhdw00000gn/T/ipykernel_9579/1772236419.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "• Epochs: 2\n",
      "• Batch size: 8\n",
      "• Total training steps: ~200\n",
      "\n",
      "Setup complete! Ready to start training...\n"
     ]
    }
   ],
   "source": [
    "# 3. Load the model and set up training\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    ")\n",
    "\n",
    "# 4. Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 5. Set up training arguments (fixed parameter names)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,              # Just 2 epochs for demo\n",
    "    per_device_train_batch_size=8,   # Small batch size for CPU\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",           # Changed from evaluation_strategy\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# 6. Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"• Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"• Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"• Total training steps: ~{len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs}\")\n",
    "\n",
    "print(\"\\nSetup complete! Ready to start training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb747d7-0e1b-48f2-bbf4-64f6d2c4a045",
   "metadata": {},
   "source": [
    "<h3>Step 5: Start Fine-tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb935b16-280d-4e94-9c60-d73b714013ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n",
      "This will take a few minutes on CPU...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hf-project/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 02:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.540275</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.773453</td>\n",
       "      <td>0.816599</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.483645</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899840</td>\n",
       "      <td>0.902576</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hf-project/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Final training loss: 0.2759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hf-project/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation results:\n",
      "• eval_loss: 0.4836\n",
      "• eval_accuracy: 0.9000\n",
      "• eval_f1: 0.8998\n",
      "• eval_precision: 0.9026\n",
      "• eval_recall: 0.9000\n",
      "• eval_runtime: 5.0113\n",
      "• eval_samples_per_second: 39.9100\n",
      "• eval_steps_per_second: 4.9890\n",
      "• epoch: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting fine-tuning...\")\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Final training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Get final evaluation results\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"\\nFinal evaluation results:\")\n",
    "for key, value in eval_result.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"• {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"• {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf76670-5478-4123-b16a-7fe0ae59b7fa",
   "metadata": {},
   "source": [
    "<h3>Step 6: Analyze Fine-tuning Results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03cf3676-c4a7-4723-b98c-c0048c3aa992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINE-TUNING RESULTS ANALYSIS\n",
      "\n",
      "PERFORMANCE COMPARISON:\n",
      "• Pre-trained DistilBERT: 90.0% accuracy\n",
      "• Fine-tuned DistilBERT:  90.0% accuracy\n",
      "• Training Loss: 0.347 → 0.154 (improved learning)\n",
      "• Validation Loss: 0.540 → 0.484 (better generalization)\n",
      "\n",
      "KEY INSIGHTS:\n",
      "• Model maintained high accuracy while reducing overfitting\n",
      "• F1-score: 89.98% (excellent balance of precision/recall)\n",
      "• Precision: 90.26% (low false positives)\n",
      "• Recall: 90.00% (good at finding true positives)\n",
      "\n",
      "TESTING FINE-TUNED MODEL:\n",
      "Custom test examples:\n",
      "1. 'This movie was absolutely fantastic! Great acting ...'\n",
      "   → POSITIVE: 1.000\n",
      "\n",
      "2. 'Worst movie I've ever seen. Terrible in every way....'\n",
      "   → NEGATIVE: 1.000\n",
      "\n",
      "3. 'The film was okay, nothing special but not bad eit...'\n",
      "   → POSITIVE: 0.701\n",
      "\n",
      "4. 'An incredible masterpiece that will be remembered ...'\n",
      "   → POSITIVE: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare before vs after fine-tuning\n",
    "print(\"FINE-TUNING RESULTS ANALYSIS\\n\")\n",
    "\n",
    "print(\"PERFORMANCE COMPARISON:\")\n",
    "print(\"• Pre-trained DistilBERT: 90.0% accuracy\")\n",
    "print(\"• Fine-tuned DistilBERT:  90.0% accuracy\")\n",
    "print(\"• Training Loss: 0.347 → 0.154 (improved learning)\")\n",
    "print(\"• Validation Loss: 0.540 → 0.484 (better generalization)\")\n",
    "\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "print(\"• Model maintained high accuracy while reducing overfitting\")\n",
    "print(\"• F1-score: 89.98% (excellent balance of precision/recall)\")\n",
    "print(\"• Precision: 90.26% (low false positives)\")\n",
    "print(\"• Recall: 90.00% (good at finding true positives)\")\n",
    "\n",
    "# Test our fine-tuned model on some new examples\n",
    "print(\"\\nTESTING FINE-TUNED MODEL:\")\n",
    "\n",
    "# Create a pipeline with our fine-tuned model\n",
    "fine_tuned_classifier = pipeline(\n",
    "    \"sentiment-analysis\", \n",
    "    model=trainer.model, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Test on some custom examples\n",
    "test_examples = [\n",
    "    \"This movie was absolutely fantastic! Great acting and plot.\",\n",
    "    \"Worst movie I've ever seen. Terrible in every way.\",\n",
    "    \"The film was okay, nothing special but not bad either.\",\n",
    "    \"An incredible masterpiece that will be remembered for years!\"\n",
    "]\n",
    "\n",
    "print(\"Custom test examples:\")\n",
    "for i, text in enumerate(test_examples, 1):\n",
    "    result = fine_tuned_classifier(text)\n",
    "    print(f\"{i}. '{text[:50]}...'\")\n",
    "    print(f\"   → {result[0]['label']}: {result[0]['score']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e2d58-a8d5-4492-814f-df699838bf17",
   "metadata": {},
   "source": [
    "<h3>Step 7: Save Model & Create Production Pipeline</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54a62c10-aec1-4ece-a197-6aca081c6580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ./fine-tuned-distilbert-imdb\n",
      "\n",
      "TESTING PRODUCTION PIPELINE:\n",
      "Single prediction: {'sentiment': 'negative', 'confidence': 0.996, 'prediction': 'NEGATIVE (99.6%)'}\n",
      "\n",
      "Batch predictions:\n",
      "• Amazing film with great characters! → positive (1.0)\n",
      "• Boring and predictable storyline. → negative (0.975)\n",
      "• Mixed feelings about this one. → positive (0.981)\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model_save_path = \"./fine-tuned-distilbert-imdb\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "# Create a production-ready class\n",
    "class MovieSentimentAnalyzer:\n",
    "    def __init__(self, model_path):\n",
    "        self.classifier = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=model_path,\n",
    "            tokenizer=model_path\n",
    "        )\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Predict sentiment with confidence score\"\"\"\n",
    "        result = self.classifier(text)[0]\n",
    "        return {\n",
    "            'sentiment': result['label'].lower(),\n",
    "            'confidence': round(result['score'], 3),\n",
    "            'prediction': f\"{result['label']} ({result['score']:.1%})\"\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, texts):\n",
    "        \"\"\"Predict sentiment for multiple texts\"\"\"\n",
    "        results = self.classifier(texts)\n",
    "        return [\n",
    "            {\n",
    "                'text': text[:50] + \"...\" if len(text) > 50 else text,\n",
    "                'sentiment': result['label'].lower(),\n",
    "                'confidence': round(result['score'], 3)\n",
    "            }\n",
    "            for text, result in zip(texts, results)\n",
    "        ]\n",
    "\n",
    "# Test our production pipeline\n",
    "print(\"\\nTESTING PRODUCTION PIPELINE:\")\n",
    "analyzer = MovieSentimentAnalyzer(model_save_path)\n",
    "\n",
    "# Test single prediction\n",
    "test_review = \"The cinematography was stunning but the plot was confusing.\"\n",
    "result = analyzer.predict(test_review)\n",
    "print(f\"Single prediction: {result}\")\n",
    "\n",
    "# Test batch prediction\n",
    "batch_reviews = [\n",
    "    \"Amazing film with great characters!\",\n",
    "    \"Boring and predictable storyline.\",\n",
    "    \"Mixed feelings about this one.\"\n",
    "]\n",
    "\n",
    "batch_results = analyzer.predict_batch(batch_reviews)\n",
    "print(f\"\\nBatch predictions:\")\n",
    "for result in batch_results:\n",
    "    print(f\"• {result['text']} → {result['sentiment']} ({result['confidence']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
